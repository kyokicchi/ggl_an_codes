{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "trainNNmodel.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "[View in Colaboratory](https://colab.research.google.com/github/kyokicchi/kaggle_codes/blob/master/trainNNmodel.ipynb)"
      ]
    },
    {
      "metadata": {
        "id": "uTLbBtpszx1d",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "61bd566d-ca36-4239-f8ae-4abe5d29082e"
      },
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from google.colab import drive\n",
        "from google.colab import files\n",
        "import pickle\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "from keras import models\n",
        "from keras import layers\n",
        "\n",
        "from keras.models import load_model\n"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "xPuIYqTaz_VT",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 121
        },
        "outputId": "4006ef33-7fb7-4742-c3b3-0e0459cd613a"
      },
      "cell_type": "code",
      "source": [
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "OfYn9ovCz7tr",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "d5f83ae4-1937-4d7b-a834-2ffff437a244"
      },
      "cell_type": "code",
      "source": [
        "%cd ../content/gdrive/My Drive/projects/\n",
        "%ls"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/gdrive/My Drive/projects\n",
            "model_LGB.sav  model_XGB.sav  user_test_n.csv\n",
            "model_NN.h5    output.csv     user_train_n.csv\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "pHlvGsudz_SD",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "s_data = 'user_train_n.csv'\n",
        "s_col_tgt = 'transactionRevenue_sum'\n",
        "l_col_drop = [s_col_tgt]\n",
        "filename = 'model_NN.h5'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "BfDpMe_zz_Pm",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "c4d432f9-32f1-4a07-8075-0b09b45e5302"
      },
      "cell_type": "code",
      "source": [
        "%%time\n",
        "df_train = pd.read_csv(s_data, index_col = 0)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<string>:2: DtypeWarning: Columns (0) have mixed types. Specify dtype option on import or set low_memory=False.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "CPU times: user 9.02 s, sys: 940 ms, total: 9.96 s\n",
            "Wall time: 12.8 s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "b0CS9HlACW-O",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "911fac9a-6c0d-419b-f9df-6742be198826"
      },
      "cell_type": "code",
      "source": [
        "%%time\n",
        "df_y = df_train[s_col_tgt]\n",
        "df_x = df_train.drop(l_col_drop, axis=1)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CPU times: user 59.6 ms, sys: 168 ms, total: 228 ms\n",
            "Wall time: 227 ms\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "497BuD1i2lys",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def build_model(N_col):\n",
        "    model = models.Sequential()\n",
        "    model.add(layers.Dense(120, activation='relu', input_shape=(N_col,)))\n",
        "    model.add(layers.Dropout(0.1))\n",
        "    model.add(layers.Dense(60, activation='relu'))\n",
        "    model.add(layers.Dropout(0.1))\n",
        "    model.add(layers.Dense(1, activation='relu'))\n",
        "    model.compile(optimizer='rmsprop', loss='mse', metrics=['mae'])\n",
        "    return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "kLBy81di22p0",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 3452
        },
        "outputId": "e4cd6c92-28d0-4fed-fe68-d93f71efc802"
      },
      "cell_type": "code",
      "source": [
        "%%time\n",
        "epochs = 100\n",
        "batch_size = df_x.shape[0] // 4\n",
        "validation_split = 0.1\n",
        "\n",
        "model = build_model(df_x.shape[1])\n",
        "\n",
        "history = model.fit(df_x,\n",
        "                    df_y,\n",
        "                    epochs=epochs,\n",
        "                    batch_size=batch_size,\n",
        "                    validation_split = validation_split,\n",
        "                    verbose=1)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 642750 samples, validate on 71417 samples\n",
            "Epoch 1/100\n",
            "642750/642750 [==============================] - 2s 4us/step - loss: 7.9026e-04 - mean_absolute_error: 0.0043 - val_loss: 2.5418e-05 - val_mean_absolute_error: 4.9837e-04\n",
            "Epoch 2/100\n",
            "642750/642750 [==============================] - 1s 2us/step - loss: 2.7971e-05 - mean_absolute_error: 5.1950e-04 - val_loss: 2.5418e-05 - val_mean_absolute_error: 4.9837e-04\n",
            "Epoch 3/100\n",
            "642750/642750 [==============================] - 1s 2us/step - loss: 2.7206e-05 - mean_absolute_error: 5.1522e-04 - val_loss: 2.5418e-05 - val_mean_absolute_error: 4.9837e-04\n",
            "Epoch 4/100\n",
            "642750/642750 [==============================] - 1s 2us/step - loss: 2.6570e-05 - mean_absolute_error: 5.1056e-04 - val_loss: 2.5418e-05 - val_mean_absolute_error: 4.9837e-04\n",
            "Epoch 5/100\n",
            "642750/642750 [==============================] - 1s 2us/step - loss: 2.6564e-05 - mean_absolute_error: 5.0994e-04 - val_loss: 2.5418e-05 - val_mean_absolute_error: 4.9837e-04\n",
            "Epoch 6/100\n",
            "642750/642750 [==============================] - 1s 2us/step - loss: 2.6013e-05 - mean_absolute_error: 5.0546e-04 - val_loss: 2.5418e-05 - val_mean_absolute_error: 4.9837e-04\n",
            "Epoch 7/100\n",
            "642750/642750 [==============================] - 1s 2us/step - loss: 2.6336e-05 - mean_absolute_error: 5.0660e-04 - val_loss: 2.5418e-05 - val_mean_absolute_error: 4.9837e-04\n",
            "Epoch 8/100\n",
            "642750/642750 [==============================] - 1s 2us/step - loss: 2.6346e-05 - mean_absolute_error: 5.0669e-04 - val_loss: 2.5418e-05 - val_mean_absolute_error: 4.9837e-04\n",
            "Epoch 9/100\n",
            "642750/642750 [==============================] - 1s 2us/step - loss: 2.5978e-05 - mean_absolute_error: 5.0342e-04 - val_loss: 2.5418e-05 - val_mean_absolute_error: 4.9837e-04\n",
            "Epoch 10/100\n",
            "642750/642750 [==============================] - 1s 2us/step - loss: 2.5808e-05 - mean_absolute_error: 5.0160e-04 - val_loss: 2.5418e-05 - val_mean_absolute_error: 4.9837e-04\n",
            "Epoch 11/100\n",
            "642750/642750 [==============================] - 1s 2us/step - loss: 2.5707e-05 - mean_absolute_error: 5.0109e-04 - val_loss: 2.5418e-05 - val_mean_absolute_error: 4.9837e-04\n",
            "Epoch 12/100\n",
            "642750/642750 [==============================] - 1s 2us/step - loss: 2.5524e-05 - mean_absolute_error: 4.9980e-04 - val_loss: 2.5418e-05 - val_mean_absolute_error: 4.9837e-04\n",
            "Epoch 13/100\n",
            "642750/642750 [==============================] - 1s 2us/step - loss: 2.5482e-05 - mean_absolute_error: 4.9837e-04 - val_loss: 2.5418e-05 - val_mean_absolute_error: 4.9837e-04\n",
            "Epoch 14/100\n",
            "642750/642750 [==============================] - 1s 2us/step - loss: 2.5439e-05 - mean_absolute_error: 4.9831e-04 - val_loss: 2.5418e-05 - val_mean_absolute_error: 4.9837e-04\n",
            "Epoch 15/100\n",
            "642750/642750 [==============================] - 1s 2us/step - loss: 2.5149e-05 - mean_absolute_error: 4.9592e-04 - val_loss: 2.5418e-05 - val_mean_absolute_error: 4.9837e-04\n",
            "Epoch 16/100\n",
            "642750/642750 [==============================] - 1s 2us/step - loss: 2.5184e-05 - mean_absolute_error: 4.9564e-04 - val_loss: 2.5418e-05 - val_mean_absolute_error: 4.9837e-04\n",
            "Epoch 17/100\n",
            "642750/642750 [==============================] - 1s 2us/step - loss: 2.4967e-05 - mean_absolute_error: 4.9440e-04 - val_loss: 2.5418e-05 - val_mean_absolute_error: 4.9837e-04\n",
            "Epoch 18/100\n",
            "642750/642750 [==============================] - 1s 2us/step - loss: 2.5191e-05 - mean_absolute_error: 4.9577e-04 - val_loss: 2.5418e-05 - val_mean_absolute_error: 4.9837e-04\n",
            "Epoch 19/100\n",
            "642750/642750 [==============================] - 1s 2us/step - loss: 2.5026e-05 - mean_absolute_error: 4.9431e-04 - val_loss: 2.5418e-05 - val_mean_absolute_error: 4.9837e-04\n",
            "Epoch 20/100\n",
            "642750/642750 [==============================] - 1s 2us/step - loss: 2.4979e-05 - mean_absolute_error: 4.9413e-04 - val_loss: 2.5418e-05 - val_mean_absolute_error: 4.9837e-04\n",
            "Epoch 21/100\n",
            "642750/642750 [==============================] - 1s 2us/step - loss: 2.4959e-05 - mean_absolute_error: 4.9381e-04 - val_loss: 2.5418e-05 - val_mean_absolute_error: 4.9837e-04\n",
            "Epoch 22/100\n",
            "642750/642750 [==============================] - 1s 2us/step - loss: 2.4902e-05 - mean_absolute_error: 4.9321e-04 - val_loss: 2.5418e-05 - val_mean_absolute_error: 4.9837e-04\n",
            "Epoch 23/100\n",
            "642750/642750 [==============================] - 1s 2us/step - loss: 2.4923e-05 - mean_absolute_error: 4.9351e-04 - val_loss: 2.5418e-05 - val_mean_absolute_error: 4.9837e-04\n",
            "Epoch 24/100\n",
            "642750/642750 [==============================] - 1s 2us/step - loss: 2.4896e-05 - mean_absolute_error: 4.9309e-04 - val_loss: 2.5418e-05 - val_mean_absolute_error: 4.9837e-04\n",
            "Epoch 25/100\n",
            "642750/642750 [==============================] - 1s 2us/step - loss: 2.4974e-05 - mean_absolute_error: 4.9376e-04 - val_loss: 2.5418e-05 - val_mean_absolute_error: 4.9837e-04\n",
            "Epoch 26/100\n",
            "642750/642750 [==============================] - 1s 2us/step - loss: 2.4914e-05 - mean_absolute_error: 4.9328e-04 - val_loss: 2.5418e-05 - val_mean_absolute_error: 4.9837e-04\n",
            "Epoch 27/100\n",
            "642750/642750 [==============================] - 1s 2us/step - loss: 2.4899e-05 - mean_absolute_error: 4.9312e-04 - val_loss: 2.5418e-05 - val_mean_absolute_error: 4.9837e-04\n",
            "Epoch 28/100\n",
            "642750/642750 [==============================] - 1s 2us/step - loss: 2.4891e-05 - mean_absolute_error: 4.9297e-04 - val_loss: 2.5418e-05 - val_mean_absolute_error: 4.9837e-04\n",
            "Epoch 29/100\n",
            "642750/642750 [==============================] - 1s 2us/step - loss: 2.4949e-05 - mean_absolute_error: 4.9348e-04 - val_loss: 2.5418e-05 - val_mean_absolute_error: 4.9837e-04\n",
            "Epoch 30/100\n",
            "642750/642750 [==============================] - 1s 2us/step - loss: 2.4903e-05 - mean_absolute_error: 4.9305e-04 - val_loss: 2.5418e-05 - val_mean_absolute_error: 4.9837e-04\n",
            "Epoch 31/100\n",
            "642750/642750 [==============================] - 1s 2us/step - loss: 2.4887e-05 - mean_absolute_error: 4.9290e-04 - val_loss: 2.5418e-05 - val_mean_absolute_error: 4.9837e-04\n",
            "Epoch 32/100\n",
            "642750/642750 [==============================] - 1s 2us/step - loss: 2.4887e-05 - mean_absolute_error: 4.9291e-04 - val_loss: 2.5418e-05 - val_mean_absolute_error: 4.9837e-04\n",
            "Epoch 33/100\n",
            "642750/642750 [==============================] - 1s 2us/step - loss: 2.4902e-05 - mean_absolute_error: 4.9309e-04 - val_loss: 2.5418e-05 - val_mean_absolute_error: 4.9837e-04\n",
            "Epoch 34/100\n",
            "642750/642750 [==============================] - 1s 2us/step - loss: 2.4889e-05 - mean_absolute_error: 4.9294e-04 - val_loss: 2.5418e-05 - val_mean_absolute_error: 4.9837e-04\n",
            "Epoch 35/100\n",
            "642750/642750 [==============================] - 1s 2us/step - loss: 2.4889e-05 - mean_absolute_error: 4.9294e-04 - val_loss: 2.5418e-05 - val_mean_absolute_error: 4.9837e-04\n",
            "Epoch 36/100\n",
            "642750/642750 [==============================] - 1s 2us/step - loss: 2.4887e-05 - mean_absolute_error: 4.9289e-04 - val_loss: 2.5418e-05 - val_mean_absolute_error: 4.9837e-04\n",
            "Epoch 37/100\n",
            "642750/642750 [==============================] - 1s 2us/step - loss: 2.4887e-05 - mean_absolute_error: 4.9289e-04 - val_loss: 2.5418e-05 - val_mean_absolute_error: 4.9837e-04\n",
            "Epoch 38/100\n",
            "642750/642750 [==============================] - 1s 2us/step - loss: 2.4898e-05 - mean_absolute_error: 4.9301e-04 - val_loss: 2.5418e-05 - val_mean_absolute_error: 4.9837e-04\n",
            "Epoch 39/100\n",
            "642750/642750 [==============================] - 1s 2us/step - loss: 2.4887e-05 - mean_absolute_error: 4.9289e-04 - val_loss: 2.5418e-05 - val_mean_absolute_error: 4.9837e-04\n",
            "Epoch 40/100\n",
            "642750/642750 [==============================] - 1s 2us/step - loss: 2.4887e-05 - mean_absolute_error: 4.9289e-04 - val_loss: 2.5418e-05 - val_mean_absolute_error: 4.9837e-04\n",
            "Epoch 41/100\n",
            "642750/642750 [==============================] - 1s 2us/step - loss: 2.4891e-05 - mean_absolute_error: 4.9297e-04 - val_loss: 2.5418e-05 - val_mean_absolute_error: 4.9837e-04\n",
            "Epoch 42/100\n",
            "642750/642750 [==============================] - 1s 2us/step - loss: 2.4887e-05 - mean_absolute_error: 4.9289e-04 - val_loss: 2.5418e-05 - val_mean_absolute_error: 4.9837e-04\n",
            "Epoch 43/100\n",
            "642750/642750 [==============================] - 1s 2us/step - loss: 2.4887e-05 - mean_absolute_error: 4.9289e-04 - val_loss: 2.5418e-05 - val_mean_absolute_error: 4.9837e-04\n",
            "Epoch 44/100\n",
            "642750/642750 [==============================] - 1s 2us/step - loss: 2.4887e-05 - mean_absolute_error: 4.9289e-04 - val_loss: 2.5418e-05 - val_mean_absolute_error: 4.9837e-04\n",
            "Epoch 45/100\n",
            "642750/642750 [==============================] - 1s 2us/step - loss: 2.4887e-05 - mean_absolute_error: 4.9289e-04 - val_loss: 2.5418e-05 - val_mean_absolute_error: 4.9837e-04\n",
            "Epoch 46/100\n",
            "642750/642750 [==============================] - 1s 2us/step - loss: 2.4887e-05 - mean_absolute_error: 4.9289e-04 - val_loss: 2.5418e-05 - val_mean_absolute_error: 4.9837e-04\n",
            "Epoch 47/100\n",
            "642750/642750 [==============================] - 1s 2us/step - loss: 2.4888e-05 - mean_absolute_error: 4.9292e-04 - val_loss: 2.5418e-05 - val_mean_absolute_error: 4.9837e-04\n",
            "Epoch 48/100\n",
            "642750/642750 [==============================] - 1s 2us/step - loss: 2.4903e-05 - mean_absolute_error: 4.9305e-04 - val_loss: 2.5418e-05 - val_mean_absolute_error: 4.9837e-04\n",
            "Epoch 49/100\n",
            "642750/642750 [==============================] - 1s 2us/step - loss: 2.4887e-05 - mean_absolute_error: 4.9289e-04 - val_loss: 2.5418e-05 - val_mean_absolute_error: 4.9837e-04\n",
            "Epoch 50/100\n",
            "642750/642750 [==============================] - 1s 2us/step - loss: 2.4887e-05 - mean_absolute_error: 4.9289e-04 - val_loss: 2.5418e-05 - val_mean_absolute_error: 4.9837e-04\n",
            "Epoch 51/100\n",
            "642750/642750 [==============================] - 1s 2us/step - loss: 2.4887e-05 - mean_absolute_error: 4.9289e-04 - val_loss: 2.5418e-05 - val_mean_absolute_error: 4.9837e-04\n",
            "Epoch 52/100\n",
            "642750/642750 [==============================] - 1s 2us/step - loss: 2.4887e-05 - mean_absolute_error: 4.9289e-04 - val_loss: 2.5418e-05 - val_mean_absolute_error: 4.9837e-04\n",
            "Epoch 53/100\n",
            "642750/642750 [==============================] - 1s 2us/step - loss: 2.4887e-05 - mean_absolute_error: 4.9289e-04 - val_loss: 2.5418e-05 - val_mean_absolute_error: 4.9837e-04\n",
            "Epoch 54/100\n",
            "642750/642750 [==============================] - 1s 2us/step - loss: 2.4887e-05 - mean_absolute_error: 4.9289e-04 - val_loss: 2.5418e-05 - val_mean_absolute_error: 4.9837e-04\n",
            "Epoch 55/100\n",
            "642750/642750 [==============================] - 1s 2us/step - loss: 2.4887e-05 - mean_absolute_error: 4.9289e-04 - val_loss: 2.5418e-05 - val_mean_absolute_error: 4.9837e-04\n",
            "Epoch 56/100\n",
            "642750/642750 [==============================] - 1s 2us/step - loss: 2.4887e-05 - mean_absolute_error: 4.9289e-04 - val_loss: 2.5418e-05 - val_mean_absolute_error: 4.9837e-04\n",
            "Epoch 57/100\n",
            "642750/642750 [==============================] - 1s 2us/step - loss: 2.4887e-05 - mean_absolute_error: 4.9289e-04 - val_loss: 2.5418e-05 - val_mean_absolute_error: 4.9837e-04\n",
            "Epoch 58/100\n",
            "642750/642750 [==============================] - 1s 2us/step - loss: 2.4887e-05 - mean_absolute_error: 4.9289e-04 - val_loss: 2.5418e-05 - val_mean_absolute_error: 4.9837e-04\n",
            "Epoch 59/100\n",
            "642750/642750 [==============================] - 1s 2us/step - loss: 2.4887e-05 - mean_absolute_error: 4.9289e-04 - val_loss: 2.5418e-05 - val_mean_absolute_error: 4.9837e-04\n",
            "Epoch 60/100\n",
            "642750/642750 [==============================] - 1s 2us/step - loss: 2.4887e-05 - mean_absolute_error: 4.9289e-04 - val_loss: 2.5418e-05 - val_mean_absolute_error: 4.9837e-04\n",
            "Epoch 61/100\n",
            "642750/642750 [==============================] - 1s 2us/step - loss: 2.4887e-05 - mean_absolute_error: 4.9289e-04 - val_loss: 2.5418e-05 - val_mean_absolute_error: 4.9837e-04\n",
            "Epoch 62/100\n",
            "642750/642750 [==============================] - 1s 2us/step - loss: 2.4887e-05 - mean_absolute_error: 4.9289e-04 - val_loss: 2.5418e-05 - val_mean_absolute_error: 4.9837e-04\n",
            "Epoch 63/100\n",
            "642750/642750 [==============================] - 1s 2us/step - loss: 2.4887e-05 - mean_absolute_error: 4.9289e-04 - val_loss: 2.5418e-05 - val_mean_absolute_error: 4.9837e-04\n",
            "Epoch 64/100\n",
            "642750/642750 [==============================] - 1s 2us/step - loss: 2.4887e-05 - mean_absolute_error: 4.9289e-04 - val_loss: 2.5418e-05 - val_mean_absolute_error: 4.9837e-04\n",
            "Epoch 65/100\n",
            "642750/642750 [==============================] - 1s 2us/step - loss: 2.4887e-05 - mean_absolute_error: 4.9289e-04 - val_loss: 2.5418e-05 - val_mean_absolute_error: 4.9837e-04\n",
            "Epoch 66/100\n",
            "642750/642750 [==============================] - 1s 2us/step - loss: 2.4887e-05 - mean_absolute_error: 4.9289e-04 - val_loss: 2.5418e-05 - val_mean_absolute_error: 4.9837e-04\n",
            "Epoch 67/100\n",
            "642750/642750 [==============================] - 1s 2us/step - loss: 2.4887e-05 - mean_absolute_error: 4.9289e-04 - val_loss: 2.5418e-05 - val_mean_absolute_error: 4.9837e-04\n",
            "Epoch 68/100\n",
            "642750/642750 [==============================] - 1s 2us/step - loss: 2.4887e-05 - mean_absolute_error: 4.9289e-04 - val_loss: 2.5418e-05 - val_mean_absolute_error: 4.9837e-04\n",
            "Epoch 69/100\n",
            "642750/642750 [==============================] - 1s 2us/step - loss: 2.4887e-05 - mean_absolute_error: 4.9289e-04 - val_loss: 2.5418e-05 - val_mean_absolute_error: 4.9837e-04\n",
            "Epoch 70/100\n",
            "642750/642750 [==============================] - 1s 2us/step - loss: 2.4887e-05 - mean_absolute_error: 4.9289e-04 - val_loss: 2.5418e-05 - val_mean_absolute_error: 4.9837e-04\n",
            "Epoch 71/100\n",
            "642750/642750 [==============================] - 1s 2us/step - loss: 2.4887e-05 - mean_absolute_error: 4.9289e-04 - val_loss: 2.5418e-05 - val_mean_absolute_error: 4.9837e-04\n",
            "Epoch 72/100\n",
            "642750/642750 [==============================] - 1s 2us/step - loss: 2.4887e-05 - mean_absolute_error: 4.9289e-04 - val_loss: 2.5418e-05 - val_mean_absolute_error: 4.9837e-04\n",
            "Epoch 73/100\n",
            "642750/642750 [==============================] - 1s 2us/step - loss: 2.4887e-05 - mean_absolute_error: 4.9289e-04 - val_loss: 2.5418e-05 - val_mean_absolute_error: 4.9837e-04\n",
            "Epoch 74/100\n",
            "642750/642750 [==============================] - 1s 2us/step - loss: 2.4887e-05 - mean_absolute_error: 4.9289e-04 - val_loss: 2.5418e-05 - val_mean_absolute_error: 4.9837e-04\n",
            "Epoch 75/100\n",
            "642750/642750 [==============================] - 1s 2us/step - loss: 2.4887e-05 - mean_absolute_error: 4.9289e-04 - val_loss: 2.5418e-05 - val_mean_absolute_error: 4.9837e-04\n",
            "Epoch 76/100\n",
            "642750/642750 [==============================] - 1s 2us/step - loss: 2.4887e-05 - mean_absolute_error: 4.9289e-04 - val_loss: 2.5418e-05 - val_mean_absolute_error: 4.9837e-04\n",
            "Epoch 77/100\n",
            "642750/642750 [==============================] - 1s 2us/step - loss: 2.4887e-05 - mean_absolute_error: 4.9289e-04 - val_loss: 2.5418e-05 - val_mean_absolute_error: 4.9837e-04\n",
            "Epoch 78/100\n",
            "642750/642750 [==============================] - 1s 2us/step - loss: 2.4887e-05 - mean_absolute_error: 4.9289e-04 - val_loss: 2.5418e-05 - val_mean_absolute_error: 4.9837e-04\n",
            "Epoch 79/100\n",
            "642750/642750 [==============================] - 1s 2us/step - loss: 2.4887e-05 - mean_absolute_error: 4.9289e-04 - val_loss: 2.5418e-05 - val_mean_absolute_error: 4.9837e-04\n",
            "Epoch 80/100\n",
            "642750/642750 [==============================] - 1s 2us/step - loss: 2.4887e-05 - mean_absolute_error: 4.9289e-04 - val_loss: 2.5418e-05 - val_mean_absolute_error: 4.9837e-04\n",
            "Epoch 81/100\n",
            "642750/642750 [==============================] - 1s 2us/step - loss: 2.4887e-05 - mean_absolute_error: 4.9289e-04 - val_loss: 2.5418e-05 - val_mean_absolute_error: 4.9837e-04\n",
            "Epoch 82/100\n",
            "642750/642750 [==============================] - 1s 2us/step - loss: 2.4887e-05 - mean_absolute_error: 4.9289e-04 - val_loss: 2.5418e-05 - val_mean_absolute_error: 4.9837e-04\n",
            "Epoch 83/100\n",
            "642750/642750 [==============================] - 1s 2us/step - loss: 2.4887e-05 - mean_absolute_error: 4.9289e-04 - val_loss: 2.5418e-05 - val_mean_absolute_error: 4.9837e-04\n",
            "Epoch 84/100\n",
            "642750/642750 [==============================] - 1s 2us/step - loss: 2.4887e-05 - mean_absolute_error: 4.9289e-04 - val_loss: 2.5418e-05 - val_mean_absolute_error: 4.9837e-04\n",
            "Epoch 85/100\n",
            "642750/642750 [==============================] - 1s 2us/step - loss: 2.4887e-05 - mean_absolute_error: 4.9289e-04 - val_loss: 2.5418e-05 - val_mean_absolute_error: 4.9837e-04\n",
            "Epoch 86/100\n",
            "642750/642750 [==============================] - 1s 2us/step - loss: 2.4887e-05 - mean_absolute_error: 4.9289e-04 - val_loss: 2.5418e-05 - val_mean_absolute_error: 4.9837e-04\n",
            "Epoch 87/100\n",
            "642750/642750 [==============================] - 1s 2us/step - loss: 2.4887e-05 - mean_absolute_error: 4.9289e-04 - val_loss: 2.5418e-05 - val_mean_absolute_error: 4.9837e-04\n",
            "Epoch 88/100\n",
            "642750/642750 [==============================] - 1s 2us/step - loss: 2.4887e-05 - mean_absolute_error: 4.9289e-04 - val_loss: 2.5418e-05 - val_mean_absolute_error: 4.9837e-04\n",
            "Epoch 89/100\n",
            "642750/642750 [==============================] - 1s 2us/step - loss: 2.4887e-05 - mean_absolute_error: 4.9289e-04 - val_loss: 2.5418e-05 - val_mean_absolute_error: 4.9837e-04\n",
            "Epoch 90/100\n",
            "642750/642750 [==============================] - 1s 2us/step - loss: 2.4887e-05 - mean_absolute_error: 4.9289e-04 - val_loss: 2.5418e-05 - val_mean_absolute_error: 4.9837e-04\n",
            "Epoch 91/100\n",
            "642750/642750 [==============================] - 1s 2us/step - loss: 2.4887e-05 - mean_absolute_error: 4.9289e-04 - val_loss: 2.5418e-05 - val_mean_absolute_error: 4.9837e-04\n",
            "Epoch 92/100\n",
            "642750/642750 [==============================] - 1s 2us/step - loss: 2.4887e-05 - mean_absolute_error: 4.9289e-04 - val_loss: 2.5418e-05 - val_mean_absolute_error: 4.9837e-04\n",
            "Epoch 93/100\n",
            "642750/642750 [==============================] - 1s 2us/step - loss: 2.4887e-05 - mean_absolute_error: 4.9289e-04 - val_loss: 2.5418e-05 - val_mean_absolute_error: 4.9837e-04\n",
            "Epoch 94/100\n",
            "642750/642750 [==============================] - 1s 2us/step - loss: 2.4887e-05 - mean_absolute_error: 4.9289e-04 - val_loss: 2.5418e-05 - val_mean_absolute_error: 4.9837e-04\n",
            "Epoch 95/100\n",
            "642750/642750 [==============================] - 1s 2us/step - loss: 2.4887e-05 - mean_absolute_error: 4.9289e-04 - val_loss: 2.5418e-05 - val_mean_absolute_error: 4.9837e-04\n",
            "Epoch 96/100\n",
            "642750/642750 [==============================] - 1s 2us/step - loss: 2.4887e-05 - mean_absolute_error: 4.9289e-04 - val_loss: 2.5418e-05 - val_mean_absolute_error: 4.9837e-04\n",
            "Epoch 97/100\n",
            "642750/642750 [==============================] - 1s 2us/step - loss: 2.4887e-05 - mean_absolute_error: 4.9289e-04 - val_loss: 2.5418e-05 - val_mean_absolute_error: 4.9837e-04\n",
            "Epoch 98/100\n",
            "642750/642750 [==============================] - 1s 2us/step - loss: 2.4887e-05 - mean_absolute_error: 4.9289e-04 - val_loss: 2.5418e-05 - val_mean_absolute_error: 4.9837e-04\n",
            "Epoch 99/100\n",
            "642750/642750 [==============================] - 1s 2us/step - loss: 2.4887e-05 - mean_absolute_error: 4.9289e-04 - val_loss: 2.5418e-05 - val_mean_absolute_error: 4.9837e-04\n",
            "Epoch 100/100\n",
            "642750/642750 [==============================] - 1s 2us/step - loss: 2.4887e-05 - mean_absolute_error: 4.9289e-04 - val_loss: 2.5418e-05 - val_mean_absolute_error: 4.9837e-04\n",
            "CPU times: user 2min 14s, sys: 6.9 s, total: 2min 21s\n",
            "Wall time: 2min 28s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "pGGlQlmjEPO1",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 6786
        },
        "outputId": "30fe2382-234a-418b-ae7c-7d80f0b1997b"
      },
      "cell_type": "code",
      "source": [
        "history.history"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'loss': [0.0007902634661624355,\n",
              "  2.7971404500492025e-05,\n",
              "  2.7206087440977422e-05,\n",
              "  2.6570200124888942e-05,\n",
              "  2.656399382752395e-05,\n",
              "  2.6012542207964492e-05,\n",
              "  2.633644892841349e-05,\n",
              "  2.634578154528853e-05,\n",
              "  2.5977695409320107e-05,\n",
              "  2.5807666102051516e-05,\n",
              "  2.5706847611421163e-05,\n",
              "  2.552410939720623e-05,\n",
              "  2.5482359780829665e-05,\n",
              "  2.5438932866929272e-05,\n",
              "  2.5148902311784938e-05,\n",
              "  2.51835186429918e-05,\n",
              "  2.4967380830907743e-05,\n",
              "  2.5190740569273993e-05,\n",
              "  2.5026136702065372e-05,\n",
              "  2.4979181303042274e-05,\n",
              "  2.495944867081872e-05,\n",
              "  2.4902459424198615e-05,\n",
              "  2.4922699868316783e-05,\n",
              "  2.4896365093582326e-05,\n",
              "  2.497442532022563e-05,\n",
              "  2.491358928501993e-05,\n",
              "  2.489937077594072e-05,\n",
              "  2.489081690112445e-05,\n",
              "  2.4948866061883896e-05,\n",
              "  2.4903227975334938e-05,\n",
              "  2.4887276900973875e-05,\n",
              "  2.4887406903219717e-05,\n",
              "  2.4901679196805874e-05,\n",
              "  2.4889139433519806e-05,\n",
              "  2.4888643788008342e-05,\n",
              "  2.4887176481984948e-05,\n",
              "  2.488717678854586e-05,\n",
              "  2.4897577653859803e-05,\n",
              "  2.488717577661043e-05,\n",
              "  2.4887175932844e-05,\n",
              "  2.489124643680959e-05,\n",
              "  2.4887175640237872e-05,\n",
              "  2.4887174776405392e-05,\n",
              "  2.4887177340211175e-05,\n",
              "  2.48871758216642e-05,\n",
              "  2.4887176923854335e-05,\n",
              "  2.4887674691200313e-05,\n",
              "  2.490319276360833e-05,\n",
              "  2.4887175878241774e-05,\n",
              "  2.4887176922340277e-05,\n",
              "  2.4887176655031614e-05,\n",
              "  2.4887174518851777e-05,\n",
              "  2.4887177008528255e-05,\n",
              "  2.4887176765874643e-05,\n",
              "  2.488717647715412e-05,\n",
              "  2.4887176123541445e-05,\n",
              "  2.4887176962260408e-05,\n",
              "  2.4887174979970896e-05,\n",
              "  2.48871763779113e-05,\n",
              "  2.4887175559370315e-05,\n",
              "  2.4887176394489504e-05,\n",
              "  2.4887176900286006e-05,\n",
              "  2.4887175625235984e-05,\n",
              "  2.4887176447436175e-05,\n",
              "  2.4887176263287377e-05,\n",
              "  2.4887176305655467e-05,\n",
              "  2.488717615878923e-05,\n",
              "  2.4887175427514455e-05,\n",
              "  2.488717513691763e-05,\n",
              "  2.4887175899158385e-05,\n",
              "  2.4887177116614856e-05,\n",
              "  2.488717662515802e-05,\n",
              "  2.4887175652387106e-05,\n",
              "  2.488717719190729e-05,\n",
              "  2.4887175238124475e-05,\n",
              "  2.4887179395350823e-05,\n",
              "  2.4887176531345993e-05,\n",
              "  2.4887176086686215e-05,\n",
              "  2.4887176376295365e-05,\n",
              "  2.488717664645102e-05,\n",
              "  2.488717464136294e-05,\n",
              "  2.4887177179591085e-05,\n",
              "  2.4887176389553965e-05,\n",
              "  2.4887176473998657e-05,\n",
              "  2.4887176808152175e-05,\n",
              "  2.4887175867340575e-05,\n",
              "  2.4887175598761234e-05,\n",
              "  2.488717640431247e-05,\n",
              "  2.4887175290004233e-05,\n",
              "  2.4887176127953433e-05,\n",
              "  2.488717620695035e-05,\n",
              "  2.4887176177648422e-05,\n",
              "  2.48871754637301e-05,\n",
              "  2.488717501547621e-05,\n",
              "  2.48871802218215e-05,\n",
              "  2.488717628527939e-05,\n",
              "  2.4887175019104285e-05,\n",
              "  2.4887176240904822e-05,\n",
              "  2.4887176558944257e-05,\n",
              "  2.4887176571631198e-05],\n",
              " 'mean_absolute_error': [0.004257014733651534,\n",
              "  0.0005195023655375315,\n",
              "  0.0005152195714394559,\n",
              "  0.0005105558126907287,\n",
              "  0.0005099417209442856,\n",
              "  0.0005054649702516555,\n",
              "  0.0005065991448341549,\n",
              "  0.0005066877916186848,\n",
              "  0.0005034207248333436,\n",
              "  0.000501595432695218,\n",
              "  0.0005010891554520173,\n",
              "  0.0004997975353932371,\n",
              "  0.00049836778861986,\n",
              "  0.0004983129544122574,\n",
              "  0.0004959193230308672,\n",
              "  0.0004956407860856581,\n",
              "  0.0004944007163698912,\n",
              "  0.0004957680018014303,\n",
              "  0.0004943100628810737,\n",
              "  0.0004941281929267758,\n",
              "  0.0004938054824100705,\n",
              "  0.0004932087307185686,\n",
              "  0.0004935082938943297,\n",
              "  0.0004930928837700766,\n",
              "  0.0004937597049234214,\n",
              "  0.0004932808507867238,\n",
              "  0.0004931243283188084,\n",
              "  0.0004929736116613511,\n",
              "  0.0004934777725457701,\n",
              "  0.0004930456514427354,\n",
              "  0.0004929001308899813,\n",
              "  0.0004929065696965035,\n",
              "  0.000493086819781044,\n",
              "  0.0004929428926911944,\n",
              "  0.000492935429023043,\n",
              "  0.0004928876172998147,\n",
              "  0.0004928876453056915,\n",
              "  0.0004930148237851785,\n",
              "  0.0004928876363934217,\n",
              "  0.0004928876416909753,\n",
              "  0.0004929672077656149,\n",
              "  0.0004928876412143563,\n",
              "  0.0004928876476072826,\n",
              "  0.0004928876392435821,\n",
              "  0.0004928876140809378,\n",
              "  0.0004928876128902051,\n",
              "  0.000492915466793033,\n",
              "  0.0004930454719696123,\n",
              "  0.0004928875984957743,\n",
              "  0.0004928876404080522,\n",
              "  0.0004928876361956379,\n",
              "  0.0004928876411754153,\n",
              "  0.0004928876203641956,\n",
              "  0.0004928876357918746,\n",
              "  0.0004928876364875592,\n",
              "  0.0004928876141515296,\n",
              "  0.0004928876414819169,\n",
              "  0.000492887620056064,\n",
              "  0.0004928876399058499,\n",
              "  0.0004928876080734816,\n",
              "  0.0004928876306830033,\n",
              "  0.0004928876051985529,\n",
              "  0.0004928876153151847,\n",
              "  0.000492887605586604,\n",
              "  0.0004928876258018461,\n",
              "  0.0004928876283255365,\n",
              "  0.0004928876578349867,\n",
              "  0.0004928876264471791,\n",
              "  0.0004928876341214437,\n",
              "  0.0004928876450284863,\n",
              "  0.0004928876210903084,\n",
              "  0.0004928876198350968,\n",
              "  0.0004928876327029518,\n",
              "  0.0004928876329850925,\n",
              "  0.0004928876417147474,\n",
              "  0.0004928897803971067,\n",
              "  0.0004928876453828942,\n",
              "  0.0004928876306789281,\n",
              "  0.0004928876376257215,\n",
              "  0.0004928876073108276,\n",
              "  0.0004928876497795536,\n",
              "  0.0004928876362590301,\n",
              "  0.0004928876401074372,\n",
              "  0.0004928876266778816,\n",
              "  0.0004928876437193912,\n",
              "  0.0004928876393132682,\n",
              "  0.0004928876388736883,\n",
              "  0.0004928876384389081,\n",
              "  0.000492887642757097,\n",
              "  0.000492887633049164,\n",
              "  0.0004928876328865176,\n",
              "  0.0004928876208714241,\n",
              "  0.0004928876415224426,\n",
              "  0.0004928876296145724,\n",
              "  0.0004928901078360056,\n",
              "  0.000492887638653672,\n",
              "  0.0004928876169668695,\n",
              "  0.0004928876302775194,\n",
              "  0.0004928876375513262,\n",
              "  0.0004928876288415946],\n",
              " 'val_loss': [2.5418403311050497e-05,\n",
              "  2.5418403311050497e-05,\n",
              "  2.5418403311050497e-05,\n",
              "  2.5418403311050497e-05,\n",
              "  2.5418403311050497e-05,\n",
              "  2.5418403311050497e-05,\n",
              "  2.5418403311050497e-05,\n",
              "  2.5418403311050497e-05,\n",
              "  2.5418403311050497e-05,\n",
              "  2.5418403311050497e-05,\n",
              "  2.5418403311050497e-05,\n",
              "  2.5418403311050497e-05,\n",
              "  2.5418403311050497e-05,\n",
              "  2.5418403311050497e-05,\n",
              "  2.5418403311050497e-05,\n",
              "  2.5418403311050497e-05,\n",
              "  2.5418403311050497e-05,\n",
              "  2.5418403311050497e-05,\n",
              "  2.5418403311050497e-05,\n",
              "  2.5418403311050497e-05,\n",
              "  2.5418403311050497e-05,\n",
              "  2.5418403311050497e-05,\n",
              "  2.5418403311050497e-05,\n",
              "  2.5418403311050497e-05,\n",
              "  2.5418403311050497e-05,\n",
              "  2.5418403311050497e-05,\n",
              "  2.5418403311050497e-05,\n",
              "  2.5418403311050497e-05,\n",
              "  2.5418403311050497e-05,\n",
              "  2.5418403311050497e-05,\n",
              "  2.5418403311050497e-05,\n",
              "  2.5418403311050497e-05,\n",
              "  2.5418403311050497e-05,\n",
              "  2.5418403311050497e-05,\n",
              "  2.5418403311050497e-05,\n",
              "  2.5418403311050497e-05,\n",
              "  2.5418403311050497e-05,\n",
              "  2.5418403311050497e-05,\n",
              "  2.5418403311050497e-05,\n",
              "  2.5418403311050497e-05,\n",
              "  2.5418403311050497e-05,\n",
              "  2.5418403311050497e-05,\n",
              "  2.5418403311050497e-05,\n",
              "  2.5418403311050497e-05,\n",
              "  2.5418403311050497e-05,\n",
              "  2.5418403311050497e-05,\n",
              "  2.5418403311050497e-05,\n",
              "  2.5418403311050497e-05,\n",
              "  2.5418403311050497e-05,\n",
              "  2.5418403311050497e-05,\n",
              "  2.5418403311050497e-05,\n",
              "  2.5418403311050497e-05,\n",
              "  2.5418403311050497e-05,\n",
              "  2.5418403311050497e-05,\n",
              "  2.5418403311050497e-05,\n",
              "  2.5418403311050497e-05,\n",
              "  2.5418403311050497e-05,\n",
              "  2.5418403311050497e-05,\n",
              "  2.5418403311050497e-05,\n",
              "  2.5418403311050497e-05,\n",
              "  2.5418403311050497e-05,\n",
              "  2.5418403311050497e-05,\n",
              "  2.5418403311050497e-05,\n",
              "  2.5418403311050497e-05,\n",
              "  2.5418403311050497e-05,\n",
              "  2.5418403311050497e-05,\n",
              "  2.5418403311050497e-05,\n",
              "  2.5418403311050497e-05,\n",
              "  2.5418403311050497e-05,\n",
              "  2.5418403311050497e-05,\n",
              "  2.5418403311050497e-05,\n",
              "  2.5418403311050497e-05,\n",
              "  2.5418403311050497e-05,\n",
              "  2.5418403311050497e-05,\n",
              "  2.5418403311050497e-05,\n",
              "  2.5418403311050497e-05,\n",
              "  2.5418403311050497e-05,\n",
              "  2.5418403311050497e-05,\n",
              "  2.5418403311050497e-05,\n",
              "  2.5418403311050497e-05,\n",
              "  2.5418403311050497e-05,\n",
              "  2.5418403311050497e-05,\n",
              "  2.5418403311050497e-05,\n",
              "  2.5418403311050497e-05,\n",
              "  2.5418403311050497e-05,\n",
              "  2.5418403311050497e-05,\n",
              "  2.5418403311050497e-05,\n",
              "  2.5418403311050497e-05,\n",
              "  2.5418403311050497e-05,\n",
              "  2.5418403311050497e-05,\n",
              "  2.5418403311050497e-05,\n",
              "  2.5418403311050497e-05,\n",
              "  2.5418403311050497e-05,\n",
              "  2.5418403311050497e-05,\n",
              "  2.5418403311050497e-05,\n",
              "  2.5418403311050497e-05,\n",
              "  2.5418403311050497e-05,\n",
              "  2.5418403311050497e-05,\n",
              "  2.5418403311050497e-05,\n",
              "  2.5418403311050497e-05],\n",
              " 'val_mean_absolute_error': [0.0004983691032975912,\n",
              "  0.0004983691032975912,\n",
              "  0.0004983691032975912,\n",
              "  0.0004983691032975912,\n",
              "  0.0004983691032975912,\n",
              "  0.0004983691032975912,\n",
              "  0.0004983691032975912,\n",
              "  0.0004983691032975912,\n",
              "  0.0004983691032975912,\n",
              "  0.0004983691032975912,\n",
              "  0.0004983691032975912,\n",
              "  0.0004983691032975912,\n",
              "  0.0004983691032975912,\n",
              "  0.0004983691032975912,\n",
              "  0.0004983691032975912,\n",
              "  0.0004983691032975912,\n",
              "  0.0004983691032975912,\n",
              "  0.0004983691032975912,\n",
              "  0.0004983691032975912,\n",
              "  0.0004983691032975912,\n",
              "  0.0004983691032975912,\n",
              "  0.0004983691032975912,\n",
              "  0.0004983691032975912,\n",
              "  0.0004983691032975912,\n",
              "  0.0004983691032975912,\n",
              "  0.0004983691032975912,\n",
              "  0.0004983691032975912,\n",
              "  0.0004983691032975912,\n",
              "  0.0004983691032975912,\n",
              "  0.0004983691032975912,\n",
              "  0.0004983691032975912,\n",
              "  0.0004983691032975912,\n",
              "  0.0004983691032975912,\n",
              "  0.0004983691032975912,\n",
              "  0.0004983691032975912,\n",
              "  0.0004983691032975912,\n",
              "  0.0004983691032975912,\n",
              "  0.0004983691032975912,\n",
              "  0.0004983691032975912,\n",
              "  0.0004983691032975912,\n",
              "  0.0004983691032975912,\n",
              "  0.0004983691032975912,\n",
              "  0.0004983691032975912,\n",
              "  0.0004983691032975912,\n",
              "  0.0004983691032975912,\n",
              "  0.0004983691032975912,\n",
              "  0.0004983691032975912,\n",
              "  0.0004983691032975912,\n",
              "  0.0004983691032975912,\n",
              "  0.0004983691032975912,\n",
              "  0.0004983691032975912,\n",
              "  0.0004983691032975912,\n",
              "  0.0004983691032975912,\n",
              "  0.0004983691032975912,\n",
              "  0.0004983691032975912,\n",
              "  0.0004983691032975912,\n",
              "  0.0004983691032975912,\n",
              "  0.0004983691032975912,\n",
              "  0.0004983691032975912,\n",
              "  0.0004983691032975912,\n",
              "  0.0004983691032975912,\n",
              "  0.0004983691032975912,\n",
              "  0.0004983691032975912,\n",
              "  0.0004983691032975912,\n",
              "  0.0004983691032975912,\n",
              "  0.0004983691032975912,\n",
              "  0.0004983691032975912,\n",
              "  0.0004983691032975912,\n",
              "  0.0004983691032975912,\n",
              "  0.0004983691032975912,\n",
              "  0.0004983691032975912,\n",
              "  0.0004983691032975912,\n",
              "  0.0004983691032975912,\n",
              "  0.0004983691032975912,\n",
              "  0.0004983691032975912,\n",
              "  0.0004983691032975912,\n",
              "  0.0004983691032975912,\n",
              "  0.0004983691032975912,\n",
              "  0.0004983691032975912,\n",
              "  0.0004983691032975912,\n",
              "  0.0004983691032975912,\n",
              "  0.0004983691032975912,\n",
              "  0.0004983691032975912,\n",
              "  0.0004983691032975912,\n",
              "  0.0004983691032975912,\n",
              "  0.0004983691032975912,\n",
              "  0.0004983691032975912,\n",
              "  0.0004983691032975912,\n",
              "  0.0004983691032975912,\n",
              "  0.0004983691032975912,\n",
              "  0.0004983691032975912,\n",
              "  0.0004983691032975912,\n",
              "  0.0004983691032975912,\n",
              "  0.0004983691032975912,\n",
              "  0.0004983691032975912,\n",
              "  0.0004983691032975912,\n",
              "  0.0004983691032975912,\n",
              "  0.0004983691032975912,\n",
              "  0.0004983691032975912,\n",
              "  0.0004983691032975912]}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "metadata": {
        "id": "E9tsa19a7Htb",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "d4ebf69a-0440-4103-e525-e8ea1cb267a7"
      },
      "cell_type": "code",
      "source": [
        "%%time\n",
        "model.save(filename)\n",
        "\n",
        "#files.download(filename)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CPU times: user 46.7 ms, sys: 6.95 ms, total: 53.7 ms\n",
            "Wall time: 459 ms\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}