{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "ca4229fe862fda4add8565cbec708d611c516b14"
   },
   "source": [
    "# Ref: Kernels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "https://www.kaggle.com/julian3833/1-quick-start-read-csv-and-flatten-json-fields\n",
    "\n",
    "https://www.kaggle.com/artgor/nn-baseline\n",
    "\n",
    "https://www.kaggle.com/ogrellier/user-level-lightgbm-lb-1-4480\n",
    "\n",
    "https://www.kaggle.com/dimitreoliveira/deep-learning-keras-ga-revenue-prediction\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# setup and import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['train.csv', 'train_parsed.csv', 'test.csv']\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pandas.io.json import json_normalize\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "path = '../data/ggl/'\n",
    "print(os.listdir(path))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parse data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_uuid": "4a23799ac3b6e7d5b1eb451ba69ab6d2fa74b585"
   },
   "outputs": [],
   "source": [
    "def load_df(csv_path, nrows=None):\n",
    "    JSON_COLUMNS = ['device', 'geoNetwork', 'totals', 'trafficSource']\n",
    "    \n",
    "    df = pd.read_csv(csv_path, \n",
    "                     converters={column: json.loads for column in JSON_COLUMNS}, \n",
    "                     dtype={'fullVisitorId': 'str'}, \n",
    "                     nrows=nrows)\n",
    "    \n",
    "    for column in JSON_COLUMNS:\n",
    "        column_as_df = json_normalize(df[column])\n",
    "        df = df.drop(column, axis=1).merge(column_as_df, right_index=True, left_index=True)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "a9f9fce9f30e29128f38851a2023569677d88cf3"
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "df_train = load_df(path + 'train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "_uuid": "7608428d61f7f89a75886136203e81cc28e3ad99"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1min 35s, sys: 2.73 s, total: 1min 38s\n",
      "Wall time: 1min 38s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "df_test = load_df(path + 'test.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "d4da91392ec96a69d73e7ae28609e340cd4f789a"
   },
   "source": [
    "# delete columns with no valid info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "_uuid": "1516939f84f16334f6079c27d24859f55ab533f8",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3.33 s, sys: 35.9 ms, total: 3.37 s\n",
      "Wall time: 3.11 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "cols_to_drop = [col for col in df_train.columns if df_train[col].nunique() == 1]\n",
    "df_train.drop(cols_to_drop, axis=1, inplace=True)\n",
    "df_test.drop([col for col in cols_to_drop if col in df_test.columns], axis=1, inplace=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "630c9e566ecd7d55591dbf5279a48079e960b97b"
   },
   "source": [
    "# apply adjustments to both train and test datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "_uuid": "53bcba9f20016db4621328051eddeb50b9b35715",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def applyEdits(df):\n",
    "    \n",
    "    # fill NA's\n",
    "\n",
    "    l_fillwithzero = ['adContent','keyword','adwordsClickInfo.adNetworkType','adwordsClickInfo.adNetworkType',\n",
    "                      'adwordsClickInfo.gclId','adwordsClickInfo.page','adwordsClickInfo.slot']\n",
    "    for x in l_fillwithzero:\n",
    "        df[x] = df[x].fillna(0)\n",
    "\n",
    "    # add / edit columns\n",
    "    df['browser_category'] = df['browser'] + '_' + df['deviceCategory']\n",
    "    df['browser_operatingSystem'] = df['browser'] + '_' + df['operatingSystem']\n",
    "    df['source_country'] = df['source'] + '_' + df['country']\n",
    "    \n",
    "    # user access stat data column\n",
    "    df['dummy'] = 1\n",
    "    df['user_cumcnt_per_day'] = (df[['fullVisitorId','date', 'dummy']].groupby(['fullVisitorId','date'])['dummy'].cumcount()+1)\n",
    "    df['user_sum_per_day'] = df[['fullVisitorId','date', 'dummy']].groupby(['fullVisitorId','date'])['dummy'].transform(sum)\n",
    "    df['user_cumcnt_sum_ratio_per_day'] = df['user_cumcnt_per_day'] / df['user_sum_per_day'] \n",
    "\n",
    "    # fix and breakdown date info\n",
    "    df['date'] = pd.to_datetime(df['date'].apply(lambda x: str(x)[:4] + '-' + str(x)[4:6] + '-' + str(x)[6:]))\n",
    "    df['year'] = df['date'].dt.year\n",
    "    df['month'] = df['date'].dt.month\n",
    "    df['day'] = df['date'].dt.day\n",
    "    df['weekday'] = df['date'].dt.weekday\n",
    "    df['weekofyear'] = df['date'].dt.weekofyear\n",
    "    df['weekend'] = df['weekday'].apply(lambda x: 1 if x>=5 else 0)\n",
    "\n",
    "    #convert to number\n",
    "    l_toNum = ['hits','pageviews']\n",
    "    for x in l_toNum:\n",
    "        df[x] = df[x].values.astype(np.int64)\n",
    "\n",
    "    #delete unecessary columns\n",
    "    l_drop = ['dummy','referralPath','browser','deviceCategory','operatingSystem','source',\n",
    "              'country','date']\n",
    "    for x in l_drop:\n",
    "        df.drop(x, axis=1, inplace=True)\n",
    "        \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "_uuid": "ad1f38ff60765f4891de78efa0d02b3f12242922"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 8.89 s, sys: 1.55 s, total: 10.4 s\n",
      "Wall time: 8.64 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "df_train = applyEdits(df_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "_uuid": "31fd2f16d0372731a73af3498f3b2917fc850905",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 7.64 s, sys: 1.39 s, total: 9.03 s\n",
      "Wall time: 7.31 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "df_test = applyEdits(df_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "073dad5a0d127383ed96406b2b2a6de70cd10272"
   },
   "source": [
    "# apply only for train dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "_uuid": "337145bd03ef1d0bcfadb9ec4b5dbc54b4202b34"
   },
   "outputs": [],
   "source": [
    "# to float and log\n",
    "df_train['transactionRevenue'] = df_train['transactionRevenue'].astype(float)\n",
    "df_train['transactionRevenue'] = np.log1p(df_train['transactionRevenue'].fillna(0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "bdbd6c3e8a8df46b78226fcff9da11d96a674cee"
   },
   "source": [
    "# category to number labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "_uuid": "ae3e561aa4b02f0c0f5585ecbf7e39d163605930"
   },
   "outputs": [],
   "source": [
    "no_use = ['fullVisitorId', 'sessionId', 'visitId', 'visitStartTime', 'transactionRevenue']\n",
    "\n",
    "cat_cols = [x for x in df_train.columns if x not in no_use and type(df_train[x][0]) == str]\n",
    "\n",
    "num_cols = [x for x in df_train.columns if x not in no_use and x not in cat_cols and type(df_train[x][0]) != str]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "_uuid": "d6cd5e1e18c145710c592cb5f8b6c22f34fe2b5f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1min 41s, sys: 22.6 s, total: 2min 4s\n",
      "Wall time: 1min 46s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "for col in cat_cols:\n",
    "    lbl = LabelEncoder()\n",
    "    lbl.fit(list(df_train[col].values.astype('str')) + list(df_test[col].values.astype('str')))\n",
    "    df_train[col] = lbl.transform(list(df_train[col].values.astype('str')))\n",
    "    df_test[col] = lbl.transform(list(df_test[col].values.astype('str')))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "def toFloat(df):\n",
    "    num_cols = [x for x in df.columns if type(df_train[x][0]) != 'str']\n",
    "    for x in num_cols:\n",
    "        df[x] = (df[x] * 1).astype(float)\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2.31 s, sys: 693 ms, total: 3 s\n",
      "Wall time: 1.66 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "df_train = toFloat(df_train)\n",
    "df_test = toFloat(df_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# resume point"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 39.6 s, sys: 352 ms, total: 40 s\n",
      "Wall time: 40.9 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "df_train.to_csv(path + 'train_wip.csv')\n",
    "df_test.to_csv(path + 'test_wip.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['train_wip.csv', 'train.csv', 'test_wip.csv', 'test.csv']\n",
      "CPU times: user 9.87 s, sys: 503 ms, total: 10.4 s\n",
      "Wall time: 10 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "import os\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pandas.io.json import json_normalize\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "path = '../data/ggl/'\n",
    "\n",
    "df_train = pd.read_csv(path +'train_wip.csv', index_col = 0, dtype={'fullVisitorId': 'str'})\n",
    "df_test = pd.read_csv(path +'test_wip.csv', index_col = 0, dtype={'fullVisitorId': 'str'})\n",
    "\n",
    "print(os.listdir(path))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# create new dataset: aggregated by users"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "_uuid": "e9f9ddbd777446eabff7364859c1782aeb43737c"
   },
   "outputs": [],
   "source": [
    "\n",
    "def aggregate_by_users(df, cat_cols):\n",
    "    aggs = {\n",
    "        'transactionRevenue': ['sum', 'size'],\n",
    "        'hits': ['sum', 'min', 'max', 'mean', 'median'],\n",
    "        'visitNumber': ['sum', 'min', 'max', 'mean', 'median'],\n",
    "        'pageviews': ['sum', 'min', 'max', 'mean', 'median'],\n",
    "        'weekend': ['mean'],\n",
    "        'year': ['mean'],\n",
    "        'isMobile': ['mean'],\n",
    "    }\n",
    "\n",
    "    for f in cat_cols + ['day', 'month', 'weekofyear']:\n",
    "        aggs[f] = ['min', 'max', 'mean', 'median', 'var', 'std']\n",
    "\n",
    "    users = df.groupby('fullVisitorId').agg(aggs)\n",
    "\n",
    "    new_columns = [\n",
    "        k + '_' + agg for k in aggs.keys() for agg in aggs[k]\n",
    "    ]\n",
    "    users.columns = new_columns\n",
    "\n",
    "    return users"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "_uuid": "02cd97d01427fd0b675ec504e14328b0007eac6a",
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 7.03 s, sys: 2.66 s, total: 9.69 s\n",
      "Wall time: 5.04 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "no_use = ['fullVisitorId', 'sessionId', 'visitId', 'visitStartTime']\n",
    "cat_cols = [x for x in df_train.columns if x not in no_use and type(df_train[x][0]) == str]\n",
    "\n",
    "\n",
    "df_user_train = aggregate_by_users(df_train, cat_cols)\n",
    "\n",
    "df_test['transactionRevenue'] = 0\n",
    "df_user_test = aggregate_by_users(df_test, cat_cols)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 30.7 s, sys: 569 ms, total: 31.3 s\n",
      "Wall time: 31.2 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "df_user_train = df_user_train.fillna(0)\n",
    "df_user_test = df_user_test.fillna(0)\n",
    "\n",
    "df_user_train.to_csv(path + 'user_train.csv')\n",
    "df_user_test.to_csv(path + 'user_test.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TODO：Normalizeバージョンを作る"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "normalized_features = ['visitNumber', 'hits', 'pageviews', \n",
    "                       'mean_hits_per_day', 'mean_pageviews_per_day', \n",
    "                       'sum_hits_per_day', 'sum_pageviews_per_day']\n",
    "\n",
    "# Normalize using Min-Max scaling\n",
    "scaler = preprocessing.MinMaxScaler()\n",
    "X_train[normalized_features] = scaler.fit_transform(X_train[normalized_features])\n",
    "X_val[normalized_features] = scaler.transform(X_val[normalized_features])\n",
    "test[normalized_features] = scaler.transform(test[normalized_features])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 以降　別ファイルで学習済みmodelからOutput作成作業用"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "/home/naoki/anaconda3/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: compiletime version 3.5 of module 'tensorflow.python.framework.fast_tensor_util' does not match runtime version 3.6\n",
      "  return f(*args, **kwds)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['model_NN.h5', 'user_train_wip.csv', 'output.csv', 'model_XGB.sav', 'user_test_wip.csv', 'train.csv', 'test_wip.csv', 'train_wip.csv', 'model_LGB.sav', 'test.csv', 'sample_submission.csv']\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pickle\n",
    "\n",
    "from keras.models import load_model\n",
    "\n",
    "\n",
    "path = '../data/ggl/'\n",
    "print(os.listdir(path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_uuid": "4d4e1b3806cfeed4d8ad2cf60db2f9bc69d44feb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 16 s, sys: 1.56 s, total: 17.6 s\n",
      "Wall time: 17.7 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "df_user_train = pd.read_csv(path +'user_train_wip.csv', index_col = 0, dtype={'fullVisitorId': 'str'})\n",
    "df_user_test = pd.read_csv(path +'user_test_wip.csv', index_col = 0, dtype={'fullVisitorId': 'str'})\n",
    "\n",
    "df_y = df_user_train['totals.transactionRevenue_sum']\n",
    "df_x = df_user_train.drop(['date_min', 'date_max', 'totals.transactionRevenue_sum'], axis=1)\n",
    "df_tgt = df_user_test.drop(['date_min', 'date_max', 'totals.transactionRevenue_sum'], axis=1)\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(df_x, df_y, random_state=1)\n",
    "x_eval, x_valid, y_eval, y_valid = train_test_split(x_test, y_test, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "_uuid": "fc7df5e25f2886ac235b1a60d0dec54a3dd6497c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 445 ms, sys: 20.2 ms, total: 465 ms\n",
      "Wall time: 454 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "models = []\n",
    "\n",
    "filename = 'model_LGB.sav'\n",
    "model_LGB = pickle.load(open(path +filename, 'rb'))\n",
    "models.append(model_LGB)\n",
    "\n",
    "filename = 'model_XGB.sav'\n",
    "model_XGB = pickle.load(open(path +filename, 'rb'))\n",
    "models.append(model_XGB)\n",
    "\n",
    "filename = 'model_NN.h5'\n",
    "model_NN = load_model(path + filename)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1.28 s, sys: 1.34 s, total: 2.63 s\n",
      "Wall time: 2.62 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "sc = StandardScaler()\n",
    "x_valid_n = pd.DataFrame(sc.fit_transform(x_valid.fillna(0)),columns=x_valid.columns)\n",
    "df_tgt_n = pd.DataFrame(sc.fit_transform(df_tgt.fillna(0)),columns=df_tgt.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "_uuid": "bb1727974a29a6ca748fdf1f0f5b9937d6b6ba55"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.85918849781\n",
      "1.96902928766\n"
     ]
    }
   ],
   "source": [
    "for model in models:\n",
    "    y_pred = model.predict(x_valid.fillna(0))\n",
    "    mse = mean_squared_error(y_valid, y_pred)\n",
    "    rmse = np.sqrt(mse)\n",
    "    print(rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.22930468212\n"
     ]
    }
   ],
   "source": [
    "y_pred = model_NN.predict(x_valid_n)\n",
    "mse = mean_squared_error(y_valid, y_pred)\n",
    "rmse = np.sqrt(mse)\n",
    "print(rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "_uuid": "c9bbcf3033c47309a2fa0b614d1b9ee8c043b039"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 36.7 s, sys: 1.49 s, total: 38.2 s\n",
      "Wall time: 11.8 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "preds = []\n",
    "for model in models:\n",
    "    pred_tmp = model.predict(df_tgt)\n",
    "    preds.append(pred_tmp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.09956587],\n",
       "       [ 0.35228747],\n",
       "       [ 0.29945278],\n",
       "       ..., \n",
       "       [-0.27611756],\n",
       "       [ 0.49377429],\n",
       "       [ 0.10136279]], dtype=float32)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_tmp = model_NN.predict(df_tgt_n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "preds.append(pred_tmp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 29.6 s, sys: 189 ms, total: 29.8 s\n",
      "Wall time: 29.8 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "df_preds = pd.DataFrame(preds).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pred_tgt = df_preds[df_preds.columns].sum(axis=1)/len(preds)\n",
    "pred_tgt[pred_tgt<0] = 0\n",
    "pred_tgt = pred_tgt.values.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_tgt['PredictedLogRevenue'] = pred_tgt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "_uuid": "d4b1490fa938064abb4a5e2c4857c34fd156d323",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_tgt[['PredictedLogRevenue']].to_csv(path + \"output.csv\", index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
